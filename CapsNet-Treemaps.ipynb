{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capsule Network for Graphical Perception of Treemaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Python and extensions*\n",
    "- **Python**: 3.7\n",
    "- **Tensorflow**: 1.15.0\n",
    "- **Numpy**: 1.18.3\n",
    "- **docopt**: 0.6.2\n",
    "- **sklearn**: 0.22.2\n",
    "- **Matplotlib**: 3.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GPU libraries*\n",
    "- **Nvidia cuDNN**: 7.4\n",
    "- **Nvidia CUDA**: 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model architecture and modifications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original tensorflow implementation of Capsule Network by thibo37800 at https://github.com/thibo73800/capsnet-traffic-sign-classifier <br>\n",
    "\n",
    "The tensorboard for the model:\n",
    "\n",
    "![Tensorboard.PNG](Tensorboard.PNG)\n",
    "\n",
    "The data for training, validation and testing is read using the data_handler class. This extracts the image data to be used by the train, test and run_experiments classes. These classes then invoke the model, which is based on the model, model_base and caps_net classes. Model handles the parsing of the data by the network using the methods in model_base. The caps_net class provides specific computation methods such as the squashing function as outlined in the CapsNet paper.\n",
    "\n",
    "*The following modifications were made to the implementation for this project:* <br><br>\n",
    "data_handler.py was modified to read image data directly from folders instead of compressed pickle files. This is because the image data was available directly, so compressing and extracting the data would be a waste of memory. The data_handler class reads the image path passed to it, and extracts the images in the given folder. It then converts the image data with two key/value pairs: 'features' which is a 4D array containing the image pixel data, and 'labels' which is a 1D array containing all label values corresponding to the images. <br><br>\n",
    "model.py was modified to use the correct amount of label values (15) for the treemap classification. An extra upsampling layer was added in the decoder method to increase the reconstructed image resolution to 48x48, which is the input resolution.<br><br>\n",
    "*The following classes were added to the implementation*:<br><br>\n",
    "run_experiments.py was created to allow running the main experiment and the sub-experiments. It is detailed in section 3.2 below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Directory guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following directories are present in the repository: <br>\n",
    "| Project root <br>\n",
    "*All python classes for training and testing the network are stored in root folder* <br>\n",
    "|-- dataset <br>\n",
    "|---- experiments<br>\n",
    "*empty folders, standard path to dataset. Experiment-data contains one individual folder for each experiment, which contain one folder for each variable value* <br>\n",
    "|-- outputs <br>\n",
    "|---- checkpoints <br>\n",
    "*Standard path used to store training checkpoints for the model* <br>\n",
    "|---- tensorboard <br>\n",
    "*Standard path to store tensorboard files for the model* <br>\n",
    "|-- settings <br>\n",
    "*Folder containing the hypterparameters in json format* <br>\n",
    "|--testresults <br>\n",
    "*Standard path to store test results in csv files, one for each experiment directory.* <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from the following link: <br>\n",
    "https://www.filehosting.org/file/details/870093/treemap-dataset.zip\n",
    "The zip file contains the following folders: <br>\n",
    "\n",
    "| training-data <br>\n",
    "| validation-data <br>\n",
    "| test-data <br>\n",
    "| test-images <br>\n",
    "| experiments <br>\n",
    "|-- baseline <br>\n",
    "|-- colors <br>\n",
    "|-- dotsize <br>\n",
    "|-- maxchildren <br>\n",
    "|-- maxnodes <br>\n",
    "|-- maxnodesize <br>\n",
    "|-- resolution <br>\n",
    "\n",
    "*All data folders contain both small resolution (96x96) and large resolution (300x300) PNG images. The small images were used for training and testing. The subfolders in the experiment root folder contain the data for the sub-experiments*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can be trained on the dataset using<br>\n",
    "~python train.py dataset/ outputs/\n",
    "Where dataset/ is the path to the training and validation dataset folders, and outputs (by default) is the path to the folder where the training checkpoints and the tensorboard will be stored.\n",
    "\n",
    "The run_experiments.py class was added to provide the functionality to run all experiments in order, and output the results in the same format to the designated folder. The folder 'testresults' will be created and the results of the experiments are stored in csv format. The titles of the respective experiment folders are the variable descriptors.\n",
    "\n",
    "The run_experiments.py class can be run using<br>\n",
    "~python run_experiments.py dataset/ ckpt/<br>\n",
    "Where dataset/ is the path to the dataset folder (containing the individual experiment folders) and ckpt/ is the path to the training checkpoint file to load the trained model.\n",
    "\n",
    "Five images can be tested and shown reconstructed (along with the softmax probabilities for label values) using the test_images.py class: <br>\n",
    "~python test_images ckpt dataset/ <br>\n",
    "Where ckpt is the path to the checkpoint file of the trained model, and dataset/ the path to the folder containing the five images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Willem Hulst\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
